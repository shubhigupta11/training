{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4543a019-dba9-4a28-b3d8-aaf49f24892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260da8aa-dcd8-47d3-a44f-8bda24b44c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "Warning: Ignoring non-Spark config property: hive.metastore.warehouse.dir\n",
      "22/03/08 02:08:12 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.80.128 instead (on interface ens33)\n",
      "22/03/08 02:08:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/03/08 02:08:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/08 02:08:14 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "22/03/08 02:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/08 02:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/03/08 02:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/03/08 02:08:15 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "# config.set(\"property\", \"value\")\n",
    "config.setMaster(\"local\").setAppName(\"MovieLenssql\")\n",
    "\n",
    "config.set(\"spark.local.dir\", \"home/ubuntu/spark-temp\")\n",
    "\n",
    "config.set(\"hive.metastore.uris\", \"thrift://localhost:9083\")\n",
    "config.set(\"hive.metastore.warehouse.dir\", \"hdfs://localhost:9000/user/hive/warehouse\")\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark =SparkSession.builder\\\n",
    "                    .config(conf=config)\\\n",
    "                    .enableHiveSupport()\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "sc= spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aebd33d-c08a-410e-a571-ddb642d3ca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|    null|               title|              genres|\n",
      "|       1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM moviedb.movies LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97f6fea-5573-43b6-b045-6188eff0065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- total_ratings: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+\n",
      "|movieId|        avg_rating|total_ratings|\n",
      "+-------+------------------+-------------+\n",
      "|    296| 4.197068403908795|          307|\n",
      "|   1090| 3.984126984126984|           63|\n",
      "| 115713|3.9107142857142856|           28|\n",
      "|   3210|3.4761904761904763|           42|\n",
      "|  88140|          3.546875|           32|\n",
      "+-------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "popularMoviesDf = spark.sql(\"\"\"\n",
    "SELECT movieId, avg(rating) as avg_rating, count(userId) as total_ratings\n",
    "FROM ratings\n",
    "GROUP BY movieId\n",
    "\"\"\")\n",
    "\n",
    "popularMoviesDf.printSchema()\n",
    "popularMoviesDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfae410d-e2ac-4bd5-9858-a3afe7d46af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW popular_movies AS\n",
    "SELECT movieId, avg(rating) as avg_rating, count(userId) as total_ratings\n",
    "FROM ratings\n",
    "GROUP BY movieId\n",
    "HAVING avg_rating >= 3.5 AND total_ratings >=100\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925f9695-3b74-4f8d-8f36-b75406078d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dropping a table\n",
    "#spark.sql(\"DROP VIEW populat_movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88717c8a-31ea-4f04-9a2d-438765a8b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+\n",
      "|database|     tableName|isTemporary|\n",
      "+--------+--------------+-----------+\n",
      "| default|        brands|      false|\n",
      "| default|     employees|      false|\n",
      "| default|        movies|      false|\n",
      "| default|      payroles|      false|\n",
      "|        |        movies|       true|\n",
      "|        |popular_movies|       true|\n",
      "|        |       ratings|       true|\n",
      "+--------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8eb61a-f4bf-46d7-8fc3-eee3a184dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+\n",
      "|movieId|        avg_rating|total_ratings|\n",
      "+-------+------------------+-------------+\n",
      "|    296| 4.197068403908795|          307|\n",
      "|  58559| 4.238255033557047|          149|\n",
      "|   1265| 3.944055944055944|          143|\n",
      "|   3996|3.8363636363636364|          110|\n",
      "|   2762| 3.893854748603352|          179|\n",
      "+-------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM popular_movies\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30709865-c864-4bcf-9e10-d5856e2ddf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================================>        (168 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------------+\n",
      "|movieId|               title|        avg_rating|total_ratings|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "|    318|Shawshank Redempt...| 4.429022082018927|          317|\n",
      "|    858|Godfather, The (1...|         4.2890625|          192|\n",
      "|   2959|   Fight Club (1999)| 4.272935779816514|          218|\n",
      "|   1221|Godfather: Part I...|  4.25968992248062|          129|\n",
      "|  48516|Departed, The (2006)| 4.252336448598131|          107|\n",
      "|   1213|   Goodfellas (1990)|              4.25|          126|\n",
      "|    912|   Casablanca (1942)|              4.24|          100|\n",
      "|  58559|Dark Knight, The ...| 4.238255033557047|          149|\n",
      "|     50|Usual Suspects, T...| 4.237745098039215|          204|\n",
      "|   1197|Princess Bride, T...| 4.232394366197183|          142|\n",
      "|    260|Star Wars: Episod...| 4.231075697211155|          251|\n",
      "|    527|Schindler's List ...|             4.225|          220|\n",
      "|   1208|Apocalypse Now (1...| 4.219626168224299|          107|\n",
      "|   2329|American History ...| 4.217054263565892|          129|\n",
      "|   1196|Star Wars: Episod...|4.2156398104265405|          211|\n",
      "|   1198|Raiders of the Lo...|            4.2075|          200|\n",
      "|   1193|One Flew Over the...| 4.203007518796992|          133|\n",
      "|   1089|Reservoir Dogs (1...| 4.202290076335878|          131|\n",
      "|    296| Pulp Fiction (1994)| 4.197068403908795|          307|\n",
      "|   2571|  Matrix, The (1999)| 4.192446043165468|          278|\n",
      "+-------+--------------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT movies.movieId, title, avg_rating, total_ratings\n",
    "FROM popular_movies\n",
    "INNER JOIN movies ON popular_movies.movieId = movies.movieId\n",
    "ORDER BY avg_rating DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e313b0b-9aad-4987-90a8-5add0cbdf769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW most_popular_movies AS \n",
    "SELECT movies.movieId, title, avg_rating, total_ratings\n",
    "FROM popular_movies\n",
    "INNER JOIN movies ON popular_movies.movieId = movies.movieId\n",
    "ORDER BY avg_rating DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2b12af-e0fd-4064-9b25-d63688dd4480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+-------------+\n",
      "|movieId|               title|       avg_rating|total_ratings|\n",
      "+-------+--------------------+-----------------+-------------+\n",
      "|    318|Shawshank Redempt...|4.429022082018927|          317|\n",
      "|    858|Godfather, The (1...|        4.2890625|          192|\n",
      "|   2959|   Fight Club (1999)|4.272935779816514|          218|\n",
      "|   1221|Godfather: Part I...| 4.25968992248062|          129|\n",
      "|  48516|Departed, The (2006)|4.252336448598131|          107|\n",
      "+-------+--------------------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM most_popular_movies\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9ea5e4-1774-4832-81da-a33dd1bce6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=>                                                      (2 + 1) / 110]22/03/08 01:51:00 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:=========>                                             (18 + 1) / 110]22/03/08 01:51:02 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeInternal(DFSOutputStream.java:577)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:573)\n",
      "[Stage 24:===========>                                           (23 + 1) / 110]22/03/08 01:51:02 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "22/03/08 01:51:02 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeInternal(DFSOutputStream.java:577)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:573)\n",
      "22/03/08 01:51:02 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:================>                                      (32 + 1) / 110]22/03/08 01:51:02 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:==================>                                    (37 + 1) / 110]22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:=====================>                                 (42 + 1) / 110]22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:=======================>                               (46 + 1) / 110]22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:=========================>                             (50 + 1) / 110]22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "22/03/08 01:51:03 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:==============================>                        (61 + 1) / 110]22/03/08 01:51:05 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:================================================>      (96 + 1) / 110]22/03/08 01:51:06 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 24:====================================================> (107 + 1) / 110]22/03/08 01:51:06 WARN DFSClient: Caught exception \n",
      "java.lang.InterruptedException\n",
      "\tat java.lang.Object.wait(Native Method)\n",
      "\tat java.lang.Thread.join(Thread.java:1252)\n",
      "\tat java.lang.Thread.join(Thread.java:1326)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)\n",
      "[Stage 27:==========================================>           (157 + 1) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+-------------+\n",
      "|movieId|               title|       avg_rating|total_ratings|\n",
      "+-------+--------------------+-----------------+-------------+\n",
      "|    318|Shawshank Redempt...|4.429022082018927|          317|\n",
      "|    858|Godfather, The (1...|        4.2890625|          192|\n",
      "|   2959|   Fight Club (1999)|4.272935779816514|          218|\n",
      "|   1221|Godfather: Part I...| 4.25968992248062|          129|\n",
      "|  48516|Departed, The (2006)|4.252336448598131|          107|\n",
      "+-------+--------------------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mostPopularMoviesDf = spark.table(\"most_popular_movies\")\n",
    "\n",
    "mostPopularMoviesDf.write\\\n",
    "                    .mode('overwrite')\\\n",
    "                    .saveAsTable(\"moviedb.most_popular_movies\")\n",
    "\n",
    "mostPopularMoviesDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057f8045-44b6-44a7-8099-008f07ee136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|database|          tableName|isTemporary|\n",
      "+--------+-------------------+-----------+\n",
      "| moviedb|              links|      false|\n",
      "| moviedb|most_popular_movies|      false|\n",
      "| moviedb|             movies|      false|\n",
      "| moviedb|            ratings|      false|\n",
      "| moviedb|            reviews|      false|\n",
      "| moviedb|               tags|      false|\n",
      "|        |most_popular_movies|       true|\n",
      "|        |             movies|       true|\n",
      "|        |     popular_movies|       true|\n",
      "|        |            ratings|       true|\n",
      "+--------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN moviedb\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4907ca-b667-4b13-b7dd-1d91d91cc698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
