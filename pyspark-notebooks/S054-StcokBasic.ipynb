{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1f71a9-e51c-440c-bded-cfa6e5f21342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f2f5e9-6c45-4b6f-9464-20d7658ca728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/27 21:45:10 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.80.128 instead (on interface ens33)\n",
      "22/03/27 21:45:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.1.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-22300dd3-4c75-4cd5-a7bc-e59f3af799d6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.6.0 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.8-1 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 614ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.8-1 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.6.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-22300dd3-4c75-4cd5-a7bc-e59f3af799d6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/13ms)\n",
      "22/03/27 21:45:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/03/27 21:45:14 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "# config.set(\"property\", \"value\")\n",
    "config.setMaster(\"local\").setAppName(\"StockBasic\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark =SparkSession.builder\\\n",
    "                    .config(conf=config)\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "sc= spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec841824-404a-47a9-bccc-7f1f261ba54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- ISIN Code: string (nullable = true)\n",
      "\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|      Company Name|          Industry|    Symbol|Series|   ISIN Code|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|    Axis Bank Ltd.|FINANCIAL SERVICES|  AXISBANK|    EQ|INE238A01034|\n",
      "|Bajaj Finance Ltd.|FINANCIAL SERVICES|BAJFINANCE|    EQ|INE296A01024|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sectorDf = spark.read.format('csv')\\\n",
    "                .option('header', True)\\\n",
    "                .option('inferSchema',True)\\\n",
    "                .load('hdfs://localhost:9000/stocks/sectors')\n",
    "\n",
    "sectorDf.printSchema()\n",
    "sectorDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f87d5c-63cf-440d-adc3-c5a0f178b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      "\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-----------+-----------+------------+----+\n",
      "|    SYMBOL|SERIES|OPEN|HIGH| LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|  TIMESTAMP|TOTALTRADES|        ISIN|_c13|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-----------+-----------+------------+----+\n",
      "| 20MICRONS|    EQ|70.1|73.6|70.1|71.85|72.05|     71.2|   219912|1.583125505E7|02-MAR-2022|       2642|INE144J01027|null|\n",
      "|21STCENMGM|    EQ|29.6|29.6|29.6| 29.6| 29.6|     30.2|     1209|      35786.4|02-MAR-2022|         45|INE253B01015|null|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-----------+-----------+------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/27 21:45:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SYMBOL, SERIES, OPEN, HIGH, LOW, CLOSE, LAST, PREVCLOSE, TOTTRDQTY, TOTTRDVAL, TIMESTAMP, TOTALTRADES, ISIN, \n",
      " Schema: SYMBOL, SERIES, OPEN, HIGH, LOW, CLOSE, LAST, PREVCLOSE, TOTTRDQTY, TOTTRDVAL, TIMESTAMP, TOTALTRADES, ISIN, _c13\n",
      "Expected: _c13 but found: \n",
      "CSV file: hdfs://localhost:9000/stocks/daily/cm02MAR2022bhav.csv\n"
     ]
    }
   ],
   "source": [
    "dailyDf = spark.read.format('csv')\\\n",
    "                .option('header', True)\\\n",
    "                .option('inferSchema',True)\\\n",
    "                .load('hdfs://localhost:9000/stocks/daily')\n",
    "\n",
    "dailyDf.printSchema()\n",
    "dailyDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6afe46-69a8-46cf-a331-31ad22caa0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyDf = dailyDf.drop('_c13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb1fe6d-ea75-4a04-b6fb-fe12e5d80fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- GAIN: double (nullable = true)\n",
      " |-- GAINP: double (nullable = true)\n",
      "\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-----------+-----------+------------+--------------------+-------------------+\n",
      "|    SYMBOL|SERIES|   OPEN|   HIGH|    LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|  TIMESTAMP|TOTALTRADES|        ISIN|                GAIN|              GAINP|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-----------+-----------+------------+--------------------+-------------------+\n",
      "| 20MICRONS|    EQ|   70.1|   73.6|   70.1|  71.85|  72.05|     71.2|   219912|1.583125505E7|02-MAR-2022|       2642|INE144J01027|                1.75| 2.4964336661911557|\n",
      "|21STCENMGM|    EQ|   29.6|   29.6|   29.6|   29.6|   29.6|     30.2|     1209|      35786.4|02-MAR-2022|         45|INE253B01015|                 0.0|                0.0|\n",
      "| 3IINFOLTD|    EQ|  51.05|  51.35|   49.1|  49.45|   49.4|    51.45|  1092731| 5.46426994E7|02-MAR-2022|       7273|INE748C01038| -1.5999999999999943|-3.1341821743388723|\n",
      "|   3MINDIA|    EQ|21480.0|21480.0|20730.0|20923.1|20925.0|  21208.4|     1823|3.829445575E7|02-MAR-2022|       1120|INE470A01017|  -556.9000000000015|-2.5926443202979583|\n",
      "|    3PLAND|    BE|   15.9|  16.15|   14.8|   15.5|  15.65|    15.55|     8318|     128580.0|02-MAR-2022|         70|INE105C01023|-0.40000000000000036|-2.5157232704402537|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-----------+-----------+------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add/ derive a column with column GAIN = CLOSE -OPEN\n",
    "# add/derive a column with column GainP = (abs (gain)/(open) * 100\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "dailyDf = dailyDf.withColumn('GAIN', col('CLOSE') -col('OPEN'))\\\n",
    "                .withColumn('GAINP', (col('GAIN') / col('OPEN')) *100)\n",
    "\n",
    "\n",
    "dailyDf.printSchema()\n",
    "dailyDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfb772-db4d-45cc-a789-f8ad420f3137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
